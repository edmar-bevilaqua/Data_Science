{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74ecd9af-520c-4ff6-b079-f0a477e25a17",
   "metadata": {},
   "source": [
    "# Machine Learning I - Aprendizado Supervisionado\n",
    "PUCRS Online - Curso de pós-graduação em Ciência de Dados e Inteligência Artificial\n",
    "\n",
    "Prof. Martin Duarte Móre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751512d6-1688-4470-9e21-e1d47d423e79",
   "metadata": {},
   "source": [
    "## Material Prático - Classificação\n",
    "\n",
    "Neste notebook, exploraremos alguns dos aspectos práticos de implementação de técnicas de Aprendizado de Máquina para a resolução de problemas de Classificação. Para tal, utilizaremos a biblioteca [`scikit-learn`](https://scikit-learn.org/stable/), que fornece a implementação de diversos algoritmos vistos durante a disciplina.\n",
    "\n",
    "Especificamente, discutiremos os seguintes conceitos:\n",
    "- Carregamento, exploração e pré-processamento de dados\n",
    "- Criação de modelos de classificação\n",
    "- Análise de desempenho\n",
    "- Fronteira de decisão\n",
    "\n",
    "Para executar os comandos abaixo, é necessário realizar a instalação de uma série de pacotes. Recomenda-se uma instalação completa do [Anaconda](https://www.anaconda.com/), que contém todos os pacotes necessários. Caso queira instalar os pacotes manualmente, o arquivo `environment.yaml` lista todas as dependências."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489b72a6-ecc1-4124-8646-cf127a48cc5a",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Antes de iniciarmos, é necessário importar todos os pacotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5a3ae-097b-421f-a3cd-72a7439d0971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega a extensão autoreload, que nos permite editar arquivos .py e reimportá-los automaticamente sempre que forem modificados\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# bibliotecas instaladas\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# implementação local\n",
    "import utils\n",
    "import visualization as vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467fcb6a-674e-4a30-b390-812f505f3112",
   "metadata": {},
   "source": [
    "## Carregando os Dados\n",
    "\n",
    "Neste Notebook, trabalharemos com um conjunto de dados chamado [Breast Cancer Wisconsin (Diagnostic)](https://pages.cs.wisc.edu/~olvi/uwmp/cancer.html#diag). Trata-se de um conjunto de dados de classificação binária (benigno/maligno) de diagnóstico de câncer de mama. Este conjunto de dados contém diversas características (*features*) anotadas para cada amostra, bem como seu respectivo rótulo.\n",
    "\n",
    "Para simplificar o problema e tornar factível a visualização da fronteira de decisão do modelo treinado, trabalharemos com um subconjunto de atributos:\n",
    "- Raio (média)\n",
    "- Textura (média)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79381928-ef4c-4997-bf6a-8bad1d164fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando dataset\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "# selecionando subconjunto com atributos mencionados acima\n",
    "X, y = data.data[['mean radius', 'mean texture']], data.target\n",
    "# salvando nomes dos atributos para utilizar nas visualizações\n",
    "feature_labels = X.columns.values\n",
    "\n",
    "# verificando os dados\n",
    "display(pd.concat([X, y], axis=1))\n",
    "fig = vis.plot_2d_data(X.to_numpy(), y, feature_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c028d57-feb3-4347-a239-0fd16c3ed71d",
   "metadata": {},
   "source": [
    "Depois de carregar os dados, devemos escolher um protocolo de avaliação para que possamos mensurar a capacidade de generalização dos modelos treinados. Neste caso, vamos utilizar o protocolo Holdout, separando os dados em conjuntos de treinamento, validação e teste. Alguns pontos importantes:\n",
    "- Os subconjuntos são gerados de maneira estratificada\n",
    "- A divisão das amostras entre cada subconjunto é feita de maneira estocástica\n",
    "- Os conjuntos de validação e teste devem possuir um número de amostras adequado para que seja possível constatar capacidade de generalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68346bf0-1048-4dfa-8f8e-2eddfdf60811",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = utils.get_dataset_splits(X, y, ratios=[0.6, 0.2, 0.2], seed=123)\n",
    "print(f'Train:\\t{len(X_train)}\\t({len(X_train) / len(X):.4f})')\n",
    "print(f'Valid:\\t{len(X_valid)}\\t({len(X_valid) / len(X):.4f})')\n",
    "print(f'Test:\\t{len(X_test)}\\t({len(X_test) / len(X):.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eba7bf-cd50-45f4-a811-496dff6095e5",
   "metadata": {},
   "source": [
    "Depois de separar os dados, podemos visualizar as distribuições dos valores dos atributos preditivos e atributo alvo, a fim de obtermos uma compreensão maior sobre os dados. Isto pode nos indicar qual procedimento de pré-processamento executar e qual medida de avaliação seria indicada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a47618d-773f-4ea7-a06c-cf03a0e4a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = vis.visualize_statistics(X_train, y_train, data.target_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b61e75-74ea-42ce-b121-b3f7a7c4eb89",
   "metadata": {},
   "source": [
    "Depois de analisar os dados, vamos escolher uma medida de avaliação e montar um *pipeline* de pré-procesamento.\n",
    "\n",
    "**Avaliação:** os modelos de classificação no Scikit-Learn já possuem uma medida de avaliação padrão em sua interface (classificação: acurácia). Para utilizar métricas diferentes, podemos consultar a [documentação](https://scikit-learn.org/stable/modules/model_evaluation.html).\n",
    "\n",
    "**Pré-processamento:** É importante ressaltar que o *pipeline* de processamento depende do algoritmo de aprendizado utilizado. Alguns algoritmos não funcionam para determinados tipos de atributos. Além disto, alguns algoritmos são sensíveis à escalas diferentes de atributos, muitas vezes sofrendo perdas significativas de desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae76594a-d8c0-496d-b8e9-56153103eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34efeff7-e27a-48a7-b067-32134a7c17ea",
   "metadata": {},
   "source": [
    "## Criando um Classificador\n",
    "\n",
    "Existem diversos algoritmos de Aprendizado de Máquina para classificação. A escolha de qual algoritmo utilizar depende de uma série de fatores:\n",
    "- Disponibilidade de recursos computacionais (treino e inferência)\n",
    "- Complexidade de modelo desejada (interpretabilidade VS desempenho)\n",
    "- Complexidade do conjunto de dados (número de atributos)\n",
    "- ...\n",
    "\n",
    "Neste Notebook, exploraremos diversos algoritmos, aplicando-os na mesma base de dados. Basta (des)comentar as linhas de código correspondentes! Seguem as documentações de cada algoritmo:\n",
    "- [k-NN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "- [Árvore de Decisão](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    "- [Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB)\n",
    "- [Regressão Logística](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) ([Polinomial](https://scikit-learn.org/stable/modules/linear_model.html#polynomial-regression-extending-linear-models-with-basis-functions))\n",
    "- [SVMs](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "\n",
    "Depois de escolhermos um algoritmo, devemos testar diversos valores de hiperparâmetros para melhorar o desempenho do modelo (sempre mantendo em mente a capacidade de generalização!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef27a6d-7617-4e35-95d4-5429ea97f060",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(\n",
    "    n_neighbors=5,\n",
    "    weights='uniform',\n",
    "    p=2,\n",
    ")\n",
    "\n",
    "# classifier = DecisionTreeClassifier(\n",
    "#     criterion='gini',\n",
    "#     max_depth=5,\n",
    "# )\n",
    "\n",
    "# classifier = GaussianNB()\n",
    "\n",
    "# classifier = LogisticRegression(\n",
    "#     penalty='l2',\n",
    "#     C=1,\n",
    "#     random_state=123,\n",
    "#     max_iter=1000,\n",
    "#     #solver='liblinear',\n",
    "# )\n",
    "\n",
    "# classifier = SVC(\n",
    "#     C=1,\n",
    "#     kernel='rbf',\n",
    "# )\n",
    "\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "score_train = classifier.score(X_train, y_train)\n",
    "score_valid = classifier.score(X_valid, y_valid)\n",
    "print(f'Accuracy (Train): {score_train:.4f}')\n",
    "print(f'Accuracy (Valid): {score_valid:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8896e995-18d7-4a45-8445-776ba484d1eb",
   "metadata": {},
   "source": [
    "## Resultado Final + Fronteira de Decisão\n",
    "\n",
    "Depois de realizarmos os experimentos para escolha do algoritmo e dos valores de hiperparâmetro, podemos realizar o teste final do modelo no conjunto de dados de teste. Podemos, também, visualizar a fronteira de decisão gerada pelo modelo treinado, a fim de compreender as diferenças entre algoritmos bem como o respectivo impacto de cada hiperparâmetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94812fff-bfeb-45d3-84e9-ee2352ede63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_test = classifier.score(X_test, y_test)\n",
    "print(f'Accuracy (Test): {score_test:.4f}')\n",
    "\n",
    "fig = vis.plot_2d_boundary(classifier, X_test, y_test, feature_labels, smooth=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4894b9-60bd-4a2c-a1ff-7ab7ba9eacf3",
   "metadata": {},
   "source": [
    "# Fim do Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
